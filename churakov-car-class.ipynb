{"cells":[{"metadata":{},"cell_type":"markdown","source":"> Это пример решения задачи с использованием Keras. Вы можете использовать этот кернер для дальнейших исследований и экспериментов.\n# Классификация изображений\n\n### Основная идея этого решения: взять предобученую на ImageNet сеть Xception и дообучить под нашу задачу. \nПо ходу решения мы будем давать вам рекомендации, которые помогут улучшить качество модели. \n\n\nУдачи и Поехали!"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport zipfile\nimport csv\nimport sys\nimport os\n\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.layers import *\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n#увеличим дефолтный размер графиков\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n#графики в svg выглядят более четкими\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline\n\nprint(os.listdir(\"../input\"))\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', tf.keras.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Устанавливаем доп библиотеки\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow.keras as keras\nimport tensorflow.keras.models as M\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.callbacks as C\nfrom tensorflow.keras.preprocessing import image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB7","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Работаем с Tensorflow v2**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Основные настройки"},{"metadata":{"trusted":true},"cell_type":"code","source":"# БАЗОВЫЙ ВАРИАНТ\n# В setup выносим основные настройки: так удобнее их перебирать в дальнейшем.\n\n#EPOCHS               = 5  # эпох на обучение\n#BATCH_SIZE           = 64 # уменьшаем batch если сеть большая, иначе не влезет в память на GPU\n#LR                   = 1e-4\n#VAL_SPLIT            = 0.15 # сколько данных выделяем на тест = 15%\n\n#CLASS_NUM            = 10  # количество классов в нашей задаче\n#IMG_SIZE             = 224 # какого размера подаем изображения в сеть\n#IMG_CHANNELS         = 3   # у RGB 3 канала\n#input_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\n#DATA_PATH = '../input/'\n#PATH = \"../working/car/\" # рабочая директория","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Вариант подбор\n\nEPOCHS               = 10  # эпох на обучение\nBATCH_SIZE           = 64 # уменьшаем batch если сеть большая, иначе не влезет в память на GPU\nLR                   = 1e-4\nVAL_SPLIT            = 0.20 # сколько данных выделяем на тест = 20%\n\nCLASS_NUM            = 10  # количество классов в нашей задаче\nIMG_SIZE             = 224 # какого размера подаем изображения в сеть\nIMG_CHANNELS         = 3   # у RGB 3 канала\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '../input/'\nPATH = \"../working/car/\" # рабочая директория","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Устаналиваем конкретное значение random seed для воспроизводимости\nos.makedirs(PATH,exist_ok=False)\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA / Анализ данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(DATA_PATH+\"train.csv\")\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.Category.value_counts()\n# распределение классов достаточно равномерное - это хорошо","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Распаковываем картинки')\n# Will unzip the files so that you can see them..\nfor data_zip in ['train.zip', 'test.zip']:\n    with zipfile.ZipFile(\"../input/\"+data_zip,\"r\") as z:\n        z.extractall(PATH)\n        \nprint(os.listdir(PATH))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Пример картинок (random sample)')\nplt.figure(figsize=(12,8))\n\nrandom_image = train_df.sample(n=9)\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values\n\nfor index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(PATH+f'train/{random_image_cat[index]}/{path}')\n    plt.subplot(3,3, index+1)\n    plt.imshow(im)\n    plt.title('Class: '+str(random_image_cat[index]))\n    plt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим на примеры картинок и их размеры чтоб понимать как их лучше обработать и сжимать."},{"metadata":{"trusted":true},"cell_type":"code","source":"image = PIL.Image.open(PATH+'/train/0/100380.jpg')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Уже догадываетесь, что означают классы?"},{"metadata":{},"cell_type":"markdown","source":"# Подготовка данных"},{"metadata":{},"cell_type":"markdown","source":"### Аугментация данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Вы помните, что аугментация данных важна, когда мы работаем с небольшим датасетом. Это как раз наш случай.\n# Чтобы лучше понять работу параметров, попробуйте их изменить. К какому результату это приведет?\n# Официальная документация: https://keras.io/preprocessing/image/\n\n#train_datagen = ImageDataGenerator(\n#    rescale=1. / 255,\n#    rotation_range = 5,\n#    width_shift_range=0.1,\n#    height_shift_range=0.1,\n#    validation_split=VAL_SPLIT, # set validation split\n#    horizontal_flip=False)\n\n#test_datagen = ImageDataGenerator(rescale=1. / 255)\n\n#Рекомендация Подключите более продвинутые библиотеки аугментации изображений (например: albumentations или imgaug, для них есть специальные \"обертки\" под Keras, например: https://github.com/mjkvaak/ImageDataAugmentor)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Подключили библиотеку аугментации изображений albumentations"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install git+https://github.com/mjkvaak/ImageDataAugmentor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from ImageDataAugmentor.image_data_augmentor import *\nimport albumentations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUGMENTATIONS = albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n    albumentations.OneOf([\n        albumentations.CenterCrop(height=224, width=200),\n        albumentations.CenterCrop(height=200, width=224),\n    ],p=0.5),\n    albumentations.OneOf([\n        albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.5),\n    albumentations.GaussianBlur(p=0.05),\n    albumentations.HueSaturationValue(p=0.5),\n    albumentations.RGBShift(p=0.5),\n    albumentations.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n    albumentations.Resize(IMG_SIZE, IMG_SIZE)\n])\n\ntrain_datagen = ImageDataAugmentor(\n        rescale=1./255,\n        augment = AUGMENTATIONS,\n        validation_split=VAL_SPLIT,\n        )\n        \ntest_datagen = ImageDataAugmentor(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Генерация данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Завернем наши данные в генератор:\n\ntrain_generator = train_datagen.flow_from_directory(\n    PATH+'train/',      # директория где расположены папки с картинками \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\ntest_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)\n\n# Обратите внимание, что для сабмита мы используем другой источник test_datagen.flow_from_dataframe. Как вы думаете, почему?","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1.Построение модели"},{"metadata":{},"cell_type":"markdown","source":"### Загружаем предобученную сеть Xception:"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = Xception(weights ='imagenet', include_top=False, input_shape = input_shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#base_model = EfficientNetB7(include_top=False, weights='imagenet', input_shape=input_shape)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"base_model.summary()\n# Рекомендация: Попробуйте и другие архитектуры сетей","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# заморозим веса и обучим только \"голову\". \n# Делаем для того, чтобы хорошо обученные признаки на Imagenet не затирались в самом начале нашего обучения\nbase_model.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# БАЗОВЫЙ\n# Устанавливаем новую \"голову\" (head)\n# ДОБАВЛЯЕМ Batch Normalization\n\n#x = base_model.output\n#x = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\n#x = Dense(256, activation='relu')(x)\n#x = BatchNormalization()(x)\n#base_model.add(L.BatchNormalization())\n#x = Dropout(0.25)(x)\n# and a logistic layer -- let's say we have 10 classes\n#predictions = Dense(CLASS_NUM, activation='softmax')(x)\n\n# this is the model we will train\n#model = Model(inputs=base_model.input, outputs=predictions)\n#model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Вариант подбора\n# Устанавливаем новую \"голову\" (head)\n# ДОБАВЛЯЕМ Batch Normalization\n\nmodel=M.Sequential()\nmodel.add(base_model)\nmodel.add(L.GlobalAveragePooling2D(),)\nmodel.add(L.Dense(256, activation='relu'))\nmodel.add(L.BatchNormalization())\nmodel.add(L.Dropout(0.25))\nmodel.add(L.Dense(CLASS_NUM, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.Обучение модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Добавим ModelCheckpoint чтоб сохранять прогресс обучения модели и можно было потом подгрузить и дообучить модель."},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\ncallbacks_list = [checkpoint]\n\n# Рекомендация 1. Добавьте другие функции из https://keras.io/callbacks/\n# Рекомендация 2. Используйте разные техники управления Learning Rate\n# https://towardsdatascience.com/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6 (eng)\n# http://teleported.in/posts/cyclic-learning-rate/ (eng)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.Обучаем голову"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)\n\n# Рекомендация: попробуйте применить transfer learning с fine-tuning","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# сохраним итоговую сеть и подгрузим лучшую итерацию в обучении (best_model)\nmodel.save('../working/model_last.hdf5')\nmodel.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим графики обучения:"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  4.FineTuning - обучение половины весов модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = True\n\n# обучаем половину весов модели\nfine_tune_at = len(base_model.layers)//2\n\n# замораживаем все веса кроме выбранных выше\nfor layer in base_model.layers[:fine_tune_at]:\n  layer.trainable =  False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"повторяем тоже что и с \"головой\""},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS               = 10  # эпох на обучение\nBATCH_SIZE           = 32 # уменьшаем batch если сеть большая, иначе не влезет в память на GPU\nLR                   = 1e-4\nVAL_SPLIT            = 0.2 # сколько данных выделяем на тест = 20%\n\nCLASS_NUM            = 10  # количество классов в нашей задаче\nIMG_SIZE             = 224 # какого размера подаем изображения в сеть\nIMG_CHANNELS         = 3   # у RGB 3 канала\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '../input/'\nPATH = \"../working/car/\" # рабочая директория\n\n# Устанавливаем конкретное значение random seed для воспроизводимости\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0\n\n# Завернем наши данные в генератор:\n\ntrain_generator = train_datagen.flow_from_directory(\n    PATH+'train/',      # директория где расположены папки с картинками \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])\n\n# Добавим ModelCheckpoint чтоб сохранять прогресс обучения модели и можно было потом подгрузить и дообучить модель.    \ncheckpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='accuracy', patience=5, restore_best_weights=True)\ncallbacks_list = [checkpoint, earlystop]\n\n# Обучаем\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n    validation_data = test_generator, \n    validation_steps = test_generator.samples//test_generator.batch_size,\n    epochs = EPOCHS,\n    callbacks = callbacks_list\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate_generator(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сохраняем модель\nmodel.save('../working/model_step2.hdf5')\nmodel.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5.FineTuning - разморозка всей сети"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = True\n\nEPOCHS               = 5  # эпох на обучение\nBATCH_SIZE           = 16 # уменьшаем batch если сеть большая, иначе не влезет в память на GPU\nLR                   = 1e-4\nVAL_SPLIT            = 0.2 # сколько данных выделяем на тест = 20%\n\nCLASS_NUM            = 10  # количество классов в нашей задаче\nIMG_SIZE             = 224 # какого размера подаем изображения в сеть\nIMG_CHANNELS         = 3   # у RGB 3 канала\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '../input/'\nPATH = \"../working/car/\" # рабочая директория\n\n# Устанавливаем конкретное значение random seed для воспроизводимости\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0\n\n# Завернем наши данные в генератор:\n\ntrain_generator = train_datagen.flow_from_directory(\n    PATH+'train/',      # директория где расположены папки с картинками \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])\n\n# Добавим ModelCheckpoint чтоб сохранять прогресс обучения модели и можно было потом подгрузить и дообучить модель.    \ncheckpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='accuracy', patience=5, restore_best_weights=True)\ncallbacks_list = [checkpoint, earlystop]\n\n# Обучаем\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n    validation_data = test_generator, \n    validation_steps = test_generator.samples//test_generator.batch_size,\n    epochs = EPOCHS,\n    callbacks = callbacks_list\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('../working/model_step3.hdf5')\nmodel.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate_generator(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6.Предсказание на тестовых данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sub_generator.samples","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sub_generator.reset()\npredictions = model.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload/','')\nsubmission.to_csv('submission.csv', index=False)\nprint('Save submit')\n\n# Рекомендация: попробуйте добавить Test Time Augmentation (TTA)\n# https://towardsdatascience.com/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Clean PATH\nimport shutil\nshutil.rmtree(PATH)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Интересно, к какому классу модель отнесет вот эти автомобили?"},{"metadata":{},"cell_type":"markdown","source":"# Что можно сделать, чтобы улучшить результат:"},{"metadata":{},"cell_type":"markdown","source":"* Примените transfer learning с fine-tuning\n* Настройте LR, optimizer, loss\n* Подберите другие переменные (размер картинки, батч и т.д.)\n* Попробуйте и другие архитектуры сетей (а не только Xception) или их ансамбли. Примеры SOTA на ImageNet  \n* \n* Добавьте Batch Normalization и поэкспериментируйте с архитектурой “головы”\n* Примените другие функции callback Keras https://keras.io/callbacks/ \n* Добавьте TTA (Test Time Augmentation)\n* Дополнительно*: Используйте разные техники управления Learning Rate (https://towardsdatascience.com/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6 (eng) http://teleported.in/posts/cyclic-learning-rate/ (eng))\n* Дополнительно*: Добавьте более продвинутые библиотеки аугментации изображений (например, Albumentations )\n\n### Удачи в соревновании!"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}